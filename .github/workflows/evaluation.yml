on:
  workflow_call:
    inputs:
      branch_with_bench_data:
        description: |
          The name of the branch that contains previous benchmark data,
          and where the new benchmark data will be saved (if desired).
          Please note that the branch must exist before the workflow is triggered
          and it can't be the same as the branch that triggered the workflow.
        required: false
        type: string
      previous_data_storage_folder:
        description: |
          The first use of this variable is in step called "Checkout the branch with previous bench res to a given folder".
          Thus, it is used to specify the folder where the previous benchmark data will be checked out.
          Afterward, in the logic of the BenchEval action, the folder and the file (file_with_previous_bench_data)
          are used to specify the location where the current benchmark data will be appended 
          so that it can be saved by executing the step "Save the current benchmark to the file with all bench data".
        required: false
        type: string
      file_with_previous_bench_data:
        description: |
          The name of the file that contains the previous benchmark data.
          This file will be also used to append the current benchmark data.
          See the description of the previous_data_storage_folder variable for more details.
        required: false
        type: string

      bucket_result_file_path:
        description: |
          The path to the file that contains the benchmark results.
          The file is located in the repository that contains the benchmark data.
        required: false
        type: string
      bucket_results_folder_path:
        description: |
          The path to the GCP bucket folder that contains the benchmark results.
        required: false
        type: string
      local_download_path_for_results:
        description: |
          The path to the local folder where the benchmark results will be downloaded.
        required: false
        type: string

      bench_group_name:
        description: 'The name of a specific benchmark. This name will be used to identify the benchmark ...'
        required: false
        type: string
      metrics_to_evaluate:
        description: |
          The metrics that will be evaluated.
        required: false
        type: string
      github_token:
        description: 'GitHub token to pull/push to repo, add benchmark info to the repo, etc.'
        required: false
        type: string
      comment_to_commit:
        description: |
          Add commit comment with the detailed benchmark info.
          Possible values are on, off, if_failed.
        required: false
        type: string
      alert_users_if_bench_failed:
        description: |
          Commas-separated list of users to alert if the benchmark failed.
        required: false
        type: string
      action_page_job_summary:
        description: 'Leave a short summary on the workflow page. Possible values are on, off, if_failed'
        required: false
        type: string
      save_current_bench_res:
        description: |
          Save the benchmark data pointed to by current_bench_res_file
          to a file located in benchmark_data_file'
        required: false
        type: string
      evaluation_method:
        description: |
          It refers to a reference point by which we determine whether the benchmark is successful or not.
          The possible values are 'previous', 'previous_successful', 'threshold', 'jump_detection', 'trend_detection_moving_ave',
          'trend_detection_deltas'
        required: true
        type: string
      bench_group_to_compare:
        description: |
          The name of the benchmark to compare to.
          This input is only used when the reference is set to 'previous' or 'previous_successful.'
          If not specified, the benchmark with the same name as the current benchmark is used.
        required: false
        type: string
      threshold_values:
        description: 'Comma-separated list of threshold values for comparison.'
        required: false
        type: string
      comparison_operators:
        description: 'Comma-separated list of operators for threshold comparison.'
        required: false
        type: string
      comparison_margins:
        description: |
          Describes by how much percentage a given value can deviate from the desired
          value (threshold or prev) to still qualify the benchmark as successful.
          If you have selected range as one of the modes in the above set of modes,
          and it is not the only function, please provide values of -1 for the remaining functions.
          For example, if you previously entered: smaller, smaller, range, and your range is 20%,
          this input should look as follows: "-1, -1, 20"
        required: false
        type: string
      threshold_upper:
        description: 'Comma-separated list of upper threshold values for range comparison.'
        required: false
        type: string
      threshold_lower:
        description: 'Comma-separated list of lower threshold values for range comparison.'
        required: false
        type: string
      jump_detection_thresholds:
        description: 'The threshold values for jump detection.'
        required: false
        type: string
      trend_thresholds:
        description: 'The threshold value for both deltas trend detection and moving average.'
        required: false
        type: string
      moving_ave_window_size:
        description: 'The window size for moving average trend detection.'
        required: false
        type: string
      trend_det_no_sufficient_data_strategy:
        description: |
          The strategy to use when there is not enough data to perform trend detection.
          The possible values are use_available and fail.
        required: false
        type: string
        default: "use_available"
      trend_det_successful_release_branch:
        description: ""
        required: false
        type: string
      failing_condition:
        description: |
        required: false
        type: string
      link_to_templated_gh_page_with_results:
        description: |
          The link to the GitHub page with the benchmark results.
          The link will be added to the comment to the commit.
        required: false
        type: string

      extra_file_uploaded_name:
        description: |
          Extra file for the eval step.
          The file will be downloaded to the root of the repository
          using download-artifact action.
          This input related to the name of the uploaded artifact.
        required: false
        type: string
      extra_file_name:
        description: |
          Extra file for the eval step.
          The file will be downloaded to the root of the repository
          using download-artifact action.
        required: false
        type: string
      extra_file_target_path:
        description: |
          Indicates where the extra file shall be moved.
        required: false
        type: string

      result_files_merge_strategy_for_each_metric:
        description: |
          The strategy to use when merging the the benchmark results from the downloaded folder.
          This should be a comma separated list of strategies. Each strategy corresponds to a metric.
          The possible values are: sum, average, max, min, median.
        required: false
        type: string

jobs:
  evaluate:
    permissions:
      contents: write
      id-token: write
    name: Evaluate the benchmark
    runs-on: ${{ vars.RUNNER }}
    defaults:
      run:
        shell: bash
    steps:
      - name: Checkout the main branch
        uses: actions/checkout@v4

      - name: Checkout the branch with previous bench res to a given folder
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.branch_with_bench_data }}
          sparse-checkout: ${{ inputs.file_with_previous_bench_data }}
          sparse-checkout-cone-mode: false
          path: ${{ inputs.previous_data_storage_folder }}

      - name: Download extra file if desired
        uses: actions/download-artifact@v3
        if: ${{ inputs.extra_file_uploaded_name != '' }}
        with:
          name: ${{ inputs.extra_file_uploaded_name }}
          path: .

      - name: Move the extra file
        if: ${{ inputs.extra_file_uploaded_name != '' }}
        run: mv ./${{ inputs.extra_file_name }} ${{ inputs.extra_file_target_path }}

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}

      - name: Setup gcloud CLI
        uses: google-github-actions/setup-gcloud@v1
        with:
          version: '>= 363.0.0'

      - name: Download results file
        uses: DawidNiezgodka/gcp-gsutil-download-helper@405c943264ade322336530c785515f341dbbcd41
        with:
          bucket_name: ${{ secrets.GCP_BUCKET_NAME }}
          target_file: ${{ inputs.bucket_result_file_path }}
          target_folder: ${{ inputs.bucket_results_folder_path }}
          local_download_path: ${{ inputs.local_download_path_for_results }}

      - name: Upload result file to the workflow artifacts
        uses: actions/upload-artifact@v3
        if: ${{ inputs.bucket_result_file_path != '' }}
        with:
          name: Current benchmark result file
          path: ${{ inputs.local_download_path_for_results }}

      - name: Upload result folder to the workflow artifacts
        uses: actions/upload-artifact@v3
        if: ${{ inputs.bucket_results_folder_path != '' }}
        with:
          name: Current benchmark result folder
          path: ${{ inputs.local_download_path_for_results }}

      - name: tree for debug
        run: tree

      - name: Evaluate the benchmark
        id: bench_eval
        uses: DawidNiezgodka/BenchEval@8f600998d2dd457c4bf17cd44f03baf18b346ae8
        with:
          folder_with_bench_data: ${{ inputs.previous_data_storage_folder }}
          file_with_bench_data: ${{ inputs.file_with_previous_bench_data }}
          folder_with_current_benchmark_results: ${{ inputs.local_download_path_for_results }}

          bench_group_name: ${{ inputs.bench_group_name }}
          result_files_merge_strategy_for_each_metric: ${{ inputs.result_files_merge_strategy_for_each_metric }}
          metrics_to_evaluate: ${{ inputs.metrics_to_evaluate }}
          comment_to_commit: ${{ inputs.comment_to_commit }}
          alert_users_if_bench_failed: ${{ inputs.alert_users_if_bench_failed }}
          action_page_job_summary: ${{ inputs.action_page_job_summary }}
          save_curr_bench_res: ${{ inputs.save_current_bench_res }}
          evaluation_method: ${{ inputs.evaluation_method }}
          benchmark_group_to_compare: ${{ inputs.bench_group_to_compare }}
          threshold_values: ${{ inputs.threshold_values }}
          comparison_operators: ${{ inputs.comparison_operators }}
          comparison_margins: ${{ inputs.comparison_margins }}
          threshold_upper: ${{ inputs.threshold_upper }}
          threshold_lower: ${{ inputs.threshold_lower }}
          jump_detection_thresholds: ${{ inputs.jump_detection_thresholds }}
          trend_thresholds: ${{ inputs.trend_thresholds }}
          moving_ave_window_size: ${{ inputs.moving_ave_window_size }}
          trend_det_no_sufficient_data_strategy: ${{ inputs.trend_det_no_sufficient_data_strategy }}
          trend_det_successful_release_branch: ${{ inputs.trend_det_successful_release_branch }}
          failing_condition: ${{ inputs.failing_condition }}
          link_to_templated_gh_page_with_results: ${{ inputs.link_to_templated_gh_page_with_results }}
          github_token: ${{ secrets.TOKEN_FOR_PRIVATE_REPOS}}
          github_context: ${{ toJson(github) }}

      - name: Save the current benchmark to the file with all bench data
        if: ${{ inputs.save_current_bench_res == 'true' }}
        working-directory: ${{ inputs.previous_data_storage_folder }}
        run: |
          git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git commit -a -m "Add changes"
          git push origin ${{ inputs.branch_with_bench_data }}

      - name: Check output and fail if needed
        if: steps.bench_eval.outputs.should_fail == 'true'
        run: |
          echo "Failing as indicated by evaluation action"
          exit 1
